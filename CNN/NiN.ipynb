{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from d2l_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2), nn.Dropout(0.5),\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on mps\n",
      "epoch 1, iter 93/469\n",
      "epoch 1, iter 186/469\n",
      "epoch 1, iter 279/469\n",
      "epoch 1, iter 372/469\n",
      "epoch 1, iter 465/469\n",
      "epoch 1, iter 469/469\n",
      "loss 2.130, train acc 0.211, test acc 0.391\n",
      "epoch 2, iter 93/469\n",
      "epoch 2, iter 186/469\n",
      "epoch 2, iter 279/469\n",
      "epoch 2, iter 372/469\n",
      "epoch 2, iter 465/469\n",
      "epoch 2, iter 469/469\n",
      "loss 1.257, train acc 0.531, test acc 0.684\n",
      "epoch 3, iter 93/469\n",
      "epoch 3, iter 186/469\n",
      "epoch 3, iter 279/469\n",
      "epoch 3, iter 372/469\n",
      "epoch 3, iter 465/469\n",
      "epoch 3, iter 469/469\n",
      "loss 0.677, train acc 0.742, test acc 0.786\n",
      "epoch 4, iter 93/469\n",
      "epoch 4, iter 186/469\n",
      "epoch 4, iter 279/469\n",
      "epoch 4, iter 372/469\n",
      "epoch 4, iter 465/469\n",
      "epoch 4, iter 469/469\n",
      "loss 0.538, train acc 0.800, test acc 0.822\n",
      "epoch 5, iter 93/469\n",
      "epoch 5, iter 186/469\n",
      "epoch 5, iter 279/469\n",
      "epoch 5, iter 372/469\n",
      "epoch 5, iter 465/469\n",
      "epoch 5, iter 469/469\n",
      "loss 0.471, train acc 0.825, test acc 0.828\n",
      "epoch 6, iter 93/469\n",
      "epoch 6, iter 186/469\n",
      "epoch 6, iter 279/469\n",
      "epoch 6, iter 372/469\n",
      "epoch 6, iter 465/469\n",
      "epoch 6, iter 469/469\n",
      "loss 0.423, train acc 0.842, test acc 0.853\n",
      "epoch 7, iter 93/469\n",
      "epoch 7, iter 186/469\n",
      "epoch 7, iter 279/469\n",
      "epoch 7, iter 372/469\n",
      "epoch 7, iter 465/469\n",
      "epoch 7, iter 469/469\n",
      "loss 0.397, train acc 0.851, test acc 0.856\n",
      "epoch 8, iter 93/469\n",
      "epoch 8, iter 186/469\n",
      "epoch 8, iter 279/469\n",
      "epoch 8, iter 372/469\n",
      "epoch 8, iter 465/469\n",
      "epoch 8, iter 469/469\n",
      "loss 0.374, train acc 0.859, test acc 0.870\n",
      "epoch 9, iter 93/469\n",
      "epoch 9, iter 186/469\n",
      "epoch 9, iter 279/469\n",
      "epoch 9, iter 372/469\n",
      "epoch 9, iter 465/469\n",
      "epoch 9, iter 469/469\n",
      "loss 0.357, train acc 0.867, test acc 0.839\n",
      "epoch 10, iter 93/469\n",
      "epoch 10, iter 186/469\n",
      "epoch 10, iter 279/469\n",
      "epoch 10, iter 372/469\n",
      "epoch 10, iter 465/469\n",
      "epoch 10, iter 469/469\n",
      "loss 0.340, train acc 0.874, test acc 0.862\n",
      "744.8 examples/sec on mps\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n",
    "train_cnn(net, train_iter, test_iter, num_epochs, lr, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
